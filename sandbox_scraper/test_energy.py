
import asyncio
from playwright.async_api import async_playwright

async def scrape_zes(page):
    print("\n--- âš¡ ZES FiyatlandÄ±rma ---")
    try:
        await page.goto("https://zes.net/tr/fiyatlandirma", timeout=60000)
        await page.wait_for_load_state("networkidle")
        content = await page.inner_text("body")
        # Regex yerine daha esnek bir arama
        lines = [l.strip() for l in content.splitlines() if "â‚º/kWh" in l]
        for line in lines[:3]:
            print(f"âœ… ZES: {line}")
    except Exception as e:
        print(f"âŒ ZES HatasÄ±: {e}")

async def scrape_trugo(page):
    print("\n--- ğŸ”‹ Trugo (Togg) FiyatlandÄ±rma ---")
    try:
        # Trugo bazen botlarÄ± sevmez, wait_until'i domcontentloaded yapalÄ±m
        await page.goto("https://www.trugo.com.tr/price", wait_until="domcontentloaded", timeout=60000)
        await asyncio.sleep(3) # JS'in fiyatlarÄ± render etmesi iÃ§in kÄ±sa bir es
        content = await page.inner_text("body")
        
        # Sadece â‚º olan ve rakam iÃ§eren satÄ±rlarÄ± yakalayalÄ±m (AC/DC ÅŸartÄ±nÄ± esnetiyoruz)
        lines = [l.strip() for l in content.splitlines() if "â‚º" in l and any(char.isdigit() for char in l)]
        
        if lines:
            for line in lines:
                print(f"âœ… Trugo: {line}")
        else:
            print("âš ï¸ Trugo verisi bulundu ama parse edilemedi. Sayfa yapÄ±sÄ± farklÄ± olabilir.")
    except Exception as e:
        print(f"âŒ Trugo HatasÄ±: {e}")

async def scrape_shell_recharge(page):
    print("\n--- ğŸš Shell Recharge ---")
    try:
        await page.goto("https://www.shell.com.tr/suruculer/shell-recharge-turkiye/fiyat-tarifesi.html", timeout=60000)
        await page.wait_for_load_state("networkidle")
        # Shell tablo kullanÄ±r
        table_text = await page.locator("table").first.inner_text()
        lines = [l.strip() for l in table_text.splitlines() if "TL" in l]
        for line in lines:
            print(f"âœ… Shell: {line}")
    except Exception as e:
        print(f"âŒ Shell HatasÄ±: {e}")

async def scrape_fuel_opet(page):
    print("\n--- â›½ AkaryakÄ±t FiyatlarÄ± (Opet Ã–rneÄŸi) ---")
    try:
        # Opet il/ilÃ§e bazlÄ± fiyatlar
        await page.goto("https://www.opet.com.tr/akaryakit-fiyatlari", timeout=60000)
        await page.wait_for_load_state("networkidle")
        
        # VarsayÄ±lan olarak Ä°stanbul verisi genelde ekranda olur
        prices = await page.locator(".fuel-price-card").all_inner_texts()
        if not prices:
            # Kart yapÄ±sÄ± yoksa tabloyu ara
            prices = await page.locator("table").first.all_inner_texts()
            
        print("âœ… Opet BÃ¶lgesel (Genel) Fiyatlar:")
        for p in prices[:3]:
            print(f"ğŸ”¹ {p.replace('\n', ' ')}")
    except Exception as e:
        print(f"âŒ Opet HatasÄ±: {e}")


async def scrape_esarj_v2(page):
    print("\n--- ğŸ”Œ EÅŸarj (ZorlamalÄ± Mod) ---")
    try:
        # URL'i ve bekleme stratejisini gÃ¼ncelledik
        await page.goto("https://esarj.com/fiyat-listesi", timeout=60000)
        # EÅŸarj tablosu bazen geÃ§ gelir, direkt tablo hÃ¼cresini bekleyelim
        await page.wait_for_selector("td", timeout=20000)
        
        # Tabloyu parÃ§a parÃ§a Ã§ekelim
        cells = await page.locator("td").all_inner_texts()
        prices = [c.strip() for c in cells if "TL" in c or "â‚º" in c]
        
        if prices:
            for p in prices[:4]:
                print(f"âœ… EÅŸarj: {p}")
        else:
            print("âš ï¸ EÅŸarj hÃ¼cresel veri bulunamadÄ±, metin taramasÄ±na geÃ§iliyor...")
            content = await page.inner_text("body")
            print(f"Ä°pucu: {content[500:800]}...") # Debug iÃ§in bir kesit
    except Exception as e:
        print(f"âŒ EÅŸarj HatasÄ±: {e}")

async def scrape_petrol_ofisi(page):
    print("\n--- â›½ Petrol Ofisi (BÃ¶lgesel Veri) ---")
    try:
        # Petrol Ofisi genelde Ä°stanbul/Merkez verisini direkt basar
        await page.goto("https://www.petrolofisi.com.tr/akaryakit-fiyatlari", timeout=60000)
        await page.wait_for_load_state("networkidle")
        
        # Fiyat tablosunu veya kartlarÄ±nÄ± bulalÄ±m
        content = await page.inner_text("body")
        lines = [l.strip() for l in content.splitlines() if "TL/LT" in l or "TL/L" in l]
        
        print("âœ… PO Fiyat Ã–rnekleri:")
        for line in lines[:5]:
            print(f"ğŸ”¹ {line}")
    except Exception as e:
        print(f"âŒ Petrol Ofisi HatasÄ±: {e}")

async def scrape_shell_fuel(page):
    print("\n--- â›½ Shell AkaryakÄ±t (BÃ¶lgesel Veri) ---")
    try:
        await page.goto("https://www.shell.com.tr/suruculer/shell-yakitlari/shell-akaryakit-fiyatlari.html", timeout=60000)
        await page.wait_for_load_state("networkidle")
        
        # Shell genelde bir widget kullanÄ±r, o yÃ¼zden bekleme sÃ¼resi Ã¶nemli
        await asyncio.sleep(3)
        content = await page.inner_text("body")
        lines = [l.strip() for l in content.splitlines() if ("KurÅŸunsuz" in l or "V-Power" in l) and "TL" in l]
        
        print("âœ… Shell AkaryakÄ±t:")
        for line in lines[:3]:
            print(f"ğŸ”¹ {line}")
    except Exception as e:
        print(f"âŒ Shell YakÄ±t HatasÄ±: {e}")

async def main():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        # SaÄŸlam bir user-agent ÅŸart
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = await context.new_page()

        # Teker teker tÃ¼m istihbaratÄ± topla
        await scrape_zes(page)
        await scrape_trugo(page)
        await scrape_shell_recharge(page)
        await scrape_fuel_opet(page)
        await scrape_esarj_v2(page)
        # Yeni devleri ekle
        await scrape_petrol_ofisi(page)
        await scrape_shell_fuel(page)
        await browser.close()

if __name__ == "__main__":
    asyncio.run(main())



